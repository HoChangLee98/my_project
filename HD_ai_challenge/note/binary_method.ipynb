{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from utils import *\n",
    "from preprocess import PreProcessor\n",
    "# from model import Model, OptunaProcessor\n",
    "\n",
    "X_train, y_train, X_valid, y_valid = load_dataset(mode='train')\n",
    "categorical_feature = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG', 'BREADTH', 'DEPTH', 'DRAUGHT', 'year']\n",
    "minmaxscale_feature = ['DIST', 'BUILT', 'DEADWEIGHT', 'GT', 'LENGTH', 'DUBAI', 'BRENT', 'WTI', 'BDI_ADJ', 'PORT_SIZE']\n",
    "\n",
    "y_pred = pd.Series(name=\"CI_HOUR\")\n",
    "    \n",
    "## preprocess data set\n",
    "preprocessing = PreProcessor(categorical_feature=categorical_feature, minmaxscale_feature=minmaxscale_feature)\n",
    "mean_values_train = preprocessing.nan_mean_fit(X_train)\n",
    "\n",
    "X_train = preprocessing.preprocess(X_train, method='mean', mean_values=mean_values_train)\n",
    "X_valid = preprocessing.preprocess(X_valid, method='mean', mean_values=mean_values_train)\n",
    "\n",
    "encoder_dict = preprocessing.categorical_process_fit(X_train)\n",
    "scaler = preprocessing.minmaxscale_process_fit(X_train)\n",
    "\n",
    "X_train = preprocessing.transform(X_train, encoder=encoder_dict, scaler=scaler)\n",
    "X_valid = preprocessing.transform(X_valid, encoder=encoder_dict, scaler=scaler)\n",
    "\n",
    "X_train, y_train = reset_data(X_train, y_train)\n",
    "X_valid, y_valid = reset_data(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0인 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set : 0.4020831389381357\n",
      "valid set : 0.3986192882349206\n"
     ]
    }
   ],
   "source": [
    "print(\"train set :\", sum(y_train['CI_HOUR'] == 0) / len(y_train))\n",
    "print(\"valid set :\", sum(y_valid['CI_HOUR'] == 0) / len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# sns.kdeplot(y_train)\n",
    "# # sns.boxplot(y_train)\n",
    "# plt.subplot(1,2,2)\n",
    "# sns.kdeplot(y_valid)\n",
    "# # sns.boxplot(y_valid)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.log1p(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(np.log1p(y_train.loc[y_train.CI_HOUR != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Problem\n",
    "* target값이 0인지 아닌지 분류하는 문제\n",
    "* 이유 : 0이 아닐 경우 target값을 로그변환시 정규분포에 근사하는 것을 확인할 수 있다.\n",
    "* Method1 : logistic\n",
    "* Method2 : Boosting Classification\n",
    "* Method3 : svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "y_train_binary = y_train[\"CI_HOUR\"].apply(lambda x : 1 if x != 0 else x).astype('int')\n",
    "y_valid_binary = y_valid[\"CI_HOUR\"].apply(lambda x : 1 if x != 0 else x).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    def __init__(\n",
    "        self, \n",
    "        X_train:pd.DataFrame, \n",
    "        y_train:pd.Series,\n",
    "        X_valid:pd.DataFrame=None, \n",
    "        y_valid:pd.Series=None,\n",
    "        classifier_name:str='lightgbm',\n",
    "        # classifier_params:dict=None\n",
    "        ):\n",
    "        self.X_train = X_train\n",
    "        self.y_train_binary = y_train[\"CI_HOUR\"].apply(lambda x : 1 if x != 0 else x).astype('int')\n",
    "        self.X_valid = X_valid \n",
    "        self.y_valid_binary = y_valid[\"CI_HOUR\"].apply(lambda x : 1 if x != 0 else x).astype('int')\n",
    "        self.classifier_name = classifier_name\n",
    "        # self.classifier_params = self.classifier_params\n",
    "        \n",
    "    def fit(self):\n",
    "        if self.classifier_name == \"logistic\":\n",
    "            classifier = LogisticRegression(\n",
    "                random_state=0, \n",
    "                class_weight='balanced', \n",
    "                max_iter=100, \n",
    "                multi_class='ovr', \n",
    "                verbose=0\n",
    "                )\n",
    "\n",
    "        elif self.classifier_name == \"lightgbm\":\n",
    "            classifier = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                class_weight='balanced',\n",
    "                is_unbalance=True,\n",
    "                )\n",
    "            \n",
    "        classifier.fit(self.X_train, self.y_train_binary)\n",
    "        y_pred_binary = classifier.predict(self.X_valid)\n",
    "        print(f\"    ##{self.classifier_name}##\")\n",
    "        print(\"accuracy : \", accuracy_score(y_true=self.y_valid_binary, y_pred=y_pred_binary))\n",
    "        print(\"f1 : \", f1_score(y_true=self.y_valid_binary, y_pred=y_pred_binary))\n",
    "        print(\"precision : \", precision_score(y_true=self.y_valid_binary, y_pred=y_pred_binary))\n",
    "        print(\"recall : \", recall_score(y_true=self.y_valid_binary, y_pred=y_pred_binary))\n",
    "        \n",
    "        return classifier\n",
    "    \n",
    "    def output_index(self, classifier:object, df:pd.Series):\n",
    "        binary_target_pred = pd.Series(classifier.predict(df))\n",
    "        print(\"Length of None Zero Target : \", sum(binary_target_pred))\n",
    "        zero_index = binary_target_pred.loc[binary_target_pred == 0].index\n",
    "        none_zero_index = binary_target_pred.loc[binary_target_pred != 0].index\n",
    "        \n",
    "        return zero_index, none_zero_index       \n",
    "    \n",
    "    def after_split_by_classifier(self, classifier:object): \n",
    "        train_zero_index, train_none_zero_index = self.output_index(classifier=classifier, df=self.X_train)\n",
    "        valid_zero_index, valid_none_zero_index = self.output_index(classifier=classifier, df=self.X_valid)\n",
    "        X_train_zero = self.X_train.loc[train_zero_index,:]\n",
    "        X_train_none_zero = self.X_train.loc[train_none_zero_index,:]\n",
    "        X_valid_zero = self.X_valid.loc[valid_zero_index,:]\n",
    "        X_valid_none_zero = self.X_valid.loc[valid_none_zero_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ##lightgbm##\n",
      "accuracy :  0.9999274264512442\n",
      "f1 :  0.9999396581634963\n",
      "precision :  0.9999849138581299\n",
      "recall :  0.9998944065648947\n",
      "Length of None Zero Target :  153789\n",
      "Length of None Zero Target :  66286\n"
     ]
    }
   ],
   "source": [
    "extractor = ClassificationModel(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_valid=X_valid, \n",
    "    y_valid=y_valid, \n",
    "    classifier_name='lightgbm',         \n",
    "    )\n",
    "classifier = extractor.fit()\n",
    "\n",
    "train_zero_index, train_none_zero_index = extractor.output_index(classifier=classifier, df=X_train)\n",
    "valid_zero_index, valid_none_zero_index = extractor.output_index(classifier=classifier, df=X_valid)\n",
    "\n",
    "X_train_zero = X_train.loc[train_zero_index,:]\n",
    "X_train_none_zero = X_train.loc[train_none_zero_index,:]\n",
    "X_valid_zero = X_train.loc[train_zero_index,:]\n",
    "X_valid_none_zero = X_train.loc[train_none_zero_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series([0,1,3,4,5,12,0,2,3,4,0])\n",
    "test.loc[[1,3,4,5]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     3\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     2\n",
       "8     3\n",
       "9     4\n",
       "10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
